{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":81,"outputs":[{"output_type":"stream","text":"['train', 'test', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)from keras.models import Sequential\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, GlobalAveragePooling2D,Conv2D\nfrom keras.layers import Activation,Dropout,Flatten,Dense,MaxPooling2D,BatchNormalization\nfrom keras.applications import ResNet50\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nimport math\n","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\nfrom keras import applications","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = \"../input/train/train\"\nY_train = \"../input/test/test\"","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train)","execution_count":85,"outputs":[{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"20"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv',low_memory=False)\ntrain_data['has_cactus'].value_counts()\ntrain_data.has_cactus = train_data.has_cactus.astype(str)","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of rows in test set is %d\"%(len(os.listdir('../input/test/test'))))\nprint(\"The number of rows in train set is %d\"%(len(os.listdir('../input/train/train'))))","execution_count":87,"outputs":[{"output_type":"stream","text":"The number of rows in test set is 4000\nThe number of rows in train set is 17500\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#datagen = ImageDataGenerator(rescale=1./255) \nbatch_size = 32","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,vertical_flip=False,\n        fill_mode='nearest')","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen = ImageDataGenerator(rescale=1/.255)","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator=train_datagen.flow_from_dataframe(train_data[:15001],directory=X_train,x_col='id',y_col='has_cactus',\n                                           class_mode='binary',batch_size=batch_size,target_size=(224,224))\n\nvalid_generator = valid_datagen.flow_from_dataframe(train_data[15000:],directory=X_train,x_col='id',y_col='has_cactus',\n                                           class_mode='binary',batch_size=batch_size,target_size=(224,224))","execution_count":91,"outputs":[{"output_type":"stream","text":"Found 15001 validated image filenames belonging to 2 classes.\nFound 2500 validated image filenames belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":92,"outputs":[{"output_type":"execute_result","execution_count":92,"data":{"text/plain":"{'0': 0, '1': 1}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import ResNet50","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\nprint('Model Loaded')\n\nbase_model.trainable = False\n","execution_count":94,"outputs":[{"output_type":"stream","text":"Model Loaded\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_model = Sequential()\ntop_model.add(base_model)\ntop_model.add(Flatten())\ntop_model.add(Dense(1024))\ntop_model.add(Activation('relu'))\ntop_model.add(Dropout(0.4))\n\ntop_model.add(Dense(1))\ntop_model.add(Activation('sigmoid'))\n\nmodel=top_model\nsgd = optimizers.SGD(lr=1e-1,decay=1e-3,momentum=0.99,nesterov=True)\nmodel.compile(optimizer=sgd,\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()\n\n\n","execution_count":95,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 7, 7, 2048)        23587712  \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 100352)            0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 1024)              102761472 \n_________________________________________________________________\nactivation_305 (Activation)  (None, 1024)              0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 1)                 1025      \n_________________________________________________________________\nactivation_306 (Activation)  (None, 1)                 0         \n=================================================================\nTotal params: 126,350,209\nTrainable params: 102,762,497\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path=\"weights.best.hdf5\"\n\ncheckpoint = ModelCheckpoint(file_path,monitor='acc', verbose=1, save_best_only=True, mode='max')\n\nearly = EarlyStopping(monitor=\"acc\", mode=\"max\", patience=15)\n\ncallbacks_list = [checkpoint, early] \n\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch= 50,\n                    epochs= 100 , verbose=2,\n                    validation_data=valid_generator,\n                    validation_steps=50,callbacks=callbacks_list)","execution_count":96,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n - 34s - loss: 3.8932 - acc: 0.7500 - val_loss: 4.0255 - val_acc: 0.7475\n\nEpoch 00001: acc improved from -inf to 0.75000, saving model to weights.best.hdf5\nEpoch 2/100\n - 18s - loss: 3.9956 - acc: 0.7494 - val_loss: 4.0363 - val_acc: 0.7468\n\nEpoch 00002: acc did not improve from 0.75000\nEpoch 3/100\n - 20s - loss: 4.1649 - acc: 0.7388 - val_loss: 3.9258 - val_acc: 0.7538\n\nEpoch 00003: acc did not improve from 0.75000\nEpoch 4/100\n - 19s - loss: 3.8959 - acc: 0.7556 - val_loss: 4.0464 - val_acc: 0.7462\n\nEpoch 00004: acc improved from 0.75000 to 0.75562, saving model to weights.best.hdf5\nEpoch 5/100\n - 20s - loss: 3.9158 - acc: 0.7544 - val_loss: 3.8842 - val_acc: 0.7564\n\nEpoch 00005: acc did not improve from 0.75562\nEpoch 6/100\n - 19s - loss: 4.0055 - acc: 0.7488 - val_loss: 4.1450 - val_acc: 0.7400\n\nEpoch 00006: acc did not improve from 0.75562\nEpoch 7/100\n - 19s - loss: 4.0454 - acc: 0.7463 - val_loss: 3.9247 - val_acc: 0.7538\n\nEpoch 00007: acc did not improve from 0.75562\nEpoch 8/100\n - 19s - loss: 3.9457 - acc: 0.7525 - val_loss: 4.2087 - val_acc: 0.7360\n\nEpoch 00008: acc did not improve from 0.75562\nEpoch 9/100\n - 19s - loss: 4.0255 - acc: 0.7475 - val_loss: 4.0852 - val_acc: 0.7438\n\nEpoch 00009: acc did not improve from 0.75562\nEpoch 10/100\n - 19s - loss: 4.0141 - acc: 0.7482 - val_loss: 4.0566 - val_acc: 0.7455\n\nEpoch 00010: acc did not improve from 0.75562\nEpoch 11/100\n - 19s - loss: 4.0553 - acc: 0.7456 - val_loss: 3.8461 - val_acc: 0.7588\n\nEpoch 00011: acc did not improve from 0.75562\nEpoch 12/100\n - 19s - loss: 3.8660 - acc: 0.7575 - val_loss: 4.1580 - val_acc: 0.7392\n\nEpoch 00012: acc improved from 0.75562 to 0.75750, saving model to weights.best.hdf5\nEpoch 13/100\n - 20s - loss: 3.9657 - acc: 0.7512 - val_loss: 3.9552 - val_acc: 0.7519\n\nEpoch 00013: acc did not improve from 0.75750\nEpoch 14/100\n - 20s - loss: 3.9756 - acc: 0.7506 - val_loss: 3.9557 - val_acc: 0.7519\n\nEpoch 00014: acc did not improve from 0.75750\nEpoch 15/100\n - 19s - loss: 3.7564 - acc: 0.7644 - val_loss: 4.1174 - val_acc: 0.7417\n\nEpoch 00015: acc improved from 0.75750 to 0.76438, saving model to weights.best.hdf5\nEpoch 16/100\n - 20s - loss: 4.2247 - acc: 0.7350 - val_loss: 4.0566 - val_acc: 0.7455\n\nEpoch 00016: acc did not improve from 0.76438\nEpoch 17/100\n - 19s - loss: 3.8959 - acc: 0.7556 - val_loss: 3.9358 - val_acc: 0.7531\n\nEpoch 00017: acc did not improve from 0.76438\nEpoch 18/100\n - 19s - loss: 3.8860 - acc: 0.7562 - val_loss: 3.9957 - val_acc: 0.7494\n\nEpoch 00018: acc did not improve from 0.76438\nEpoch 19/100\n - 19s - loss: 3.8412 - acc: 0.7591 - val_loss: 3.9653 - val_acc: 0.7513\n\nEpoch 00019: acc did not improve from 0.76438\nEpoch 20/100\n - 19s - loss: 4.0155 - acc: 0.7481 - val_loss: 3.9956 - val_acc: 0.7494\n\nEpoch 00020: acc did not improve from 0.76438\nEpoch 21/100\n - 19s - loss: 4.0653 - acc: 0.7450 - val_loss: 4.0972 - val_acc: 0.7430\n\nEpoch 00021: acc did not improve from 0.76438\nEpoch 22/100\n - 19s - loss: 4.0055 - acc: 0.7488 - val_loss: 4.0653 - val_acc: 0.7450\n\nEpoch 00022: acc did not improve from 0.76438\nEpoch 23/100\n - 19s - loss: 4.1649 - acc: 0.7388 - val_loss: 3.8740 - val_acc: 0.7570\n\nEpoch 00023: acc did not improve from 0.76438\nEpoch 24/100\n - 19s - loss: 3.4974 - acc: 0.7806 - val_loss: 4.0464 - val_acc: 0.7462\n\nEpoch 00024: acc improved from 0.76438 to 0.78063, saving model to weights.best.hdf5\nEpoch 25/100\n - 20s - loss: 4.0454 - acc: 0.7463 - val_loss: 3.9457 - val_acc: 0.7525\n\nEpoch 00025: acc did not improve from 0.78063\nEpoch 26/100\n - 19s - loss: 3.9059 - acc: 0.7550 - val_loss: 4.0160 - val_acc: 0.7481\n\nEpoch 00026: acc did not improve from 0.78063\nEpoch 27/100\n - 19s - loss: 4.0055 - acc: 0.7488 - val_loss: 4.1073 - val_acc: 0.7424\n\nEpoch 00027: acc did not improve from 0.78063\nEpoch 28/100\n - 19s - loss: 4.0653 - acc: 0.7450 - val_loss: 4.0952 - val_acc: 0.7431\n\nEpoch 00028: acc did not improve from 0.78063\nEpoch 29/100\n - 19s - loss: 3.8556 - acc: 0.7582 - val_loss: 3.8943 - val_acc: 0.7557\n\nEpoch 00029: acc did not improve from 0.78063\nEpoch 30/100\n - 19s - loss: 4.2945 - acc: 0.7306 - val_loss: 4.0653 - val_acc: 0.7450\n\nEpoch 00030: acc did not improve from 0.78063\nEpoch 31/100\n - 19s - loss: 3.9557 - acc: 0.7519 - val_loss: 4.0769 - val_acc: 0.7443\n\nEpoch 00031: acc did not improve from 0.78063\nEpoch 32/100\n - 19s - loss: 4.0155 - acc: 0.7481 - val_loss: 4.0464 - val_acc: 0.7462\n\nEpoch 00032: acc did not improve from 0.78063\nEpoch 33/100\n - 19s - loss: 3.8262 - acc: 0.7600 - val_loss: 3.9457 - val_acc: 0.7525\n\nEpoch 00033: acc did not improve from 0.78063\nEpoch 34/100\n - 19s - loss: 4.0354 - acc: 0.7469 - val_loss: 3.9247 - val_acc: 0.7538\n\nEpoch 00034: acc did not improve from 0.78063\nEpoch 35/100\n - 19s - loss: 3.8760 - acc: 0.7569 - val_loss: 4.1986 - val_acc: 0.7366\n\nEpoch 00035: acc did not improve from 0.78063\nEpoch 36/100\n - 19s - loss: 3.8062 - acc: 0.7612 - val_loss: 3.9457 - val_acc: 0.7525\n\nEpoch 00036: acc did not improve from 0.78063\nEpoch 37/100\n - 19s - loss: 3.9258 - acc: 0.7537 - val_loss: 4.0464 - val_acc: 0.7462\n\nEpoch 00037: acc did not improve from 0.78063\nEpoch 38/100\n - 19s - loss: 4.1292 - acc: 0.7410 - val_loss: 3.8842 - val_acc: 0.7564\n\nEpoch 00038: acc did not improve from 0.78063\nEpoch 39/100\n - 19s - loss: 3.8461 - acc: 0.7588 - val_loss: 4.1151 - val_acc: 0.7419\n\nEpoch 00039: acc did not improve from 0.78063\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}